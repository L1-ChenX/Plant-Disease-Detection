\renewcommand{\fig}[3]{
	\begin{figure}[!htb]
		\centering
		\includegraphics[width=#2\textwidth]{#1.png}
		\caption{#3}
		\label{#1-zh}
	\end{figure}
}
\renewcommand{\tab}[3]{
	\begin{table}[!htb]
		\centering
		\caption{#3}
		\includegraphics[width=#2\textwidth]{#1.png}
		\label{#1-zh}
	\end{table}
}

\newcommand{\mySection}[2]{
	% 1. 手动增加章节计数
	\refstepcounter{section}   
	% 2. 显式锚点，便于超链接跳转
	\phantomsection
	% 3. 将编号+标题写入目录 (#1是标题, \thesection是章节编号)
	\addcontentsline{toc}{section}{\protect\numberline{\thesection} #1}
	% 4. 在正文中显示编号与标题
	\section*{\thesection\quad #1}
	% 5. 设置 \label 便于 \ref 等引用
	\label{#2}
}

\newcommand{\mySubsection}[1]{%
	\refstepcounter{subsection}  
	\phantomsection
	\addcontentsline{toc}{subsection}{\protect\numberline{\thesubsection} #1}
	\subsection*{\thesubsection\quad #1}
}

\zihao{-4}\songti
\noindent 作者：Sk Mahmudul Hassan,Arnab Kumar Maji\\
\noindent 出处：IEEE Access, 2022, 10: 5390-5401.
\vspace{2ex}

\begin{center}
    \zihao{4}\textbf{利用新型卷积神经网络的植物病害识别}
\end{center}

\noindent\textbf{摘要：} 及时识别植物病害对于防止作物受损至关重要。卷积神经网络（CNN），尤其是深度学习方法，广泛应用于机器视觉和模式识别任务中。研究人员提出了多种深度学习模型用于植物病害识别。然而，这些模型通常需要大量参数，导致训练时间较长，并且难以在小型设备上实现。在本文中，我们提出了一种基于Inception层和残差连接的新型深度学习模型。通过引入深度可分离卷积以减少参数数量。该模型在三个不同的植物病害数据集上进行了训练和测试。在PlantVillage数据集上，模型达到了99.39\%的准确率；在水稻病害数据集上达到了99.66\%；在木薯病害数据集上达到了76.59\%。与现有的深度学习模型相比，该模型在减少参数数量的同时实现了更高的准确率。

\noindent\textbf{关键词：} 植物病害，机器学习，深度学习，深度卷积，逐点卷积
\mySection{引言}{s1-zh}
作物病害主要由细菌和真菌引起，对作物的产量和质量产生负面影响。及时、早期识别病害症状是保护作物的重大挑战。在发展中国家，农学家和专家通过目视方式识别大面积农场的病害是主要方法，但此方法耗时且成本高昂。利用智能设备进行自动病害识别是一种有前景的方法，可以降低整体成本并提高识别效率。

近年来，深度学习，尤其是卷积神经网络（CNN）在农业领域备受关注，包括植物检测、水果检测、病害识别、杂草识别和害虫分类等应用。CNN模型之所以受到青睐，是因为其能够自动从数据集中提取适当的特征。多种流行的深度学习模型如AlexNet、GoogleNet、VGGNet、ResNet和DenseNet已被开发用于植物病害识别。

在当前背景下，基于深度学习架构的实时应用及病害识别正逐渐受到关注。深度学习模型的参数数量和计算成本取决于模型的深度及使用的滤波器数量。由于深度学习模型通常需要大量参数，因此计算成本较高，这给在小型设备上部署带来了困难。近年来，研究人员在高性能GPU和服务器上实现了深度学习架构。然而，在农业领域，使用GPU等昂贵设备并不可行。因此，迫切需要开发具有更少参数、更低功耗和计算量的应用程序。

针对上述问题，我们设计了一种新型轻量级深度学习模型用于植物病害识别。本文提出了一种基于Inception和ResNet的CNN架构，该模型参数较少但能够有效识别植物病害。Inception架构通过不同滤波器尺寸的多次卷积提取更优特征。为了应对梯度消失问题，我们引入了残差连接。此外，我们用深度可分离卷积替代了标准卷积，从而在不影响性能的前提下降低了参数数量和计算复杂度。模型在三个不同数据集上进行训练和测试，验证了其性能。主要贡献：

提出一种结合Inception和残差连接的新型CNN架构，能够提取更优特征并提供更高的性能。

本文用深度可分离卷积取代标准卷积，显著减少参数数量，同时保持模型性能。

该模型的参数数量少于其他深度学习架构，执行速度更快。

为验证模型的健壮性，我们在三个不同的植物病害数据集上评估了其性能。这些数据集包括在实验室和田间条件下采集的图像。结果表明，我们提出的模型优于现有的深度学习模型。

本文其余部分组织如下：第\ref{s2-zh}节介绍现有的植物病害识别相关文献。第\ref{s3-zh}节讨论材料与方法。第\ref{s4-zh}节展示实验结果与讨论。最后，第\ref{s5-zh}节为结论部分。

\mySection{相关研究}{s2-zh}
%\section{相关研究} \label{s2-zh}
本节对基于深度学习模型的植物病害识别的近期研究进行了讨论和综述。Mohanty等人使用AlexNet和GoogleNet识别了14种不同植物物种的26种疾病。在训练模型时，他们采用了迁移学习和从零开始学习两种方法。通过GoogleNet，他们获得了99.34\$的最高准确率。Ferentinos使用五种不同的预训练深度学习模型（VGG、AlexNet、AlexNetOWTBn、Overfeat和GoogleNet）识别了58种植物叶片病害。Geetharamani和Pandian使用了九层深度卷积神经网络（CNN）对植物病害进行识别，达到了96.46\%的准确率。受AlexNet和GoogleNet架构启发，Liu等人通过将AlexNet的全连接层替换为Inception层设计了一个模型，识别了四种不同的苹果叶片病害，记录的准确率为97.62\%。

Ahmad等人使用了四种不同的预训练深度学习架构（VGG16、VGG19、ResNet和InceptionV3）识别不同番茄叶片病害。他们通过微调网络参数获得了最优结果。其中InceptionV3在实验室和田间图像上的最高准确率分别达到了99.60\%和93.70\%。Rangarajan和Purushothaman使用预训练的VGG16模型识别不同的茄子病害。在特征提取过程中使用VGG16，而在分类过程中采用了多类支持向量机（SVM）。为验证模型的健壮性，他们使用了三种不同的颜色模型图像，即RGB、YCbCr和HSV。在RGB图像中，他们记录的最高准确率为99.4\%。

Too等人使用了多种预训练深度学习模型，并在植物病害识别和分类中对模型参数进行了微调。通过DenseNet架构，他们获得了99.75\%的最高测试准确率。Sethy等人使用基于深度特征的SVM分类器识别了水稻叶片病害。他们使用了11个深度CNN模型提取特征，并使用SVM进行分类。ResNet50模型的深度特征与SVM结合后表现最佳，F1分数为98.38\%。Rangarajan Aravind和Raja使用了六种不同的预训练深度学习架构，识别了四种植物的10种不同病害。在所有架构中，VGG16在测试数据集上的最高准确率达到了90\%。

Ramacharan等人通过InceptionV3迁移学习识别了木薯植物的三种疾病和两种害虫损害。所使用的数据集包含了具有多片叶子的单个图像。在包含单片叶子图像的数据集中，获得的准确率高于包含多片叶子图像的数据集。随后，Ramacharan等人使用移动设备识别木薯植物的六种不同病害。他们采用MobileNet深度学习架构进行网络训练，并使用病害叶片图像和视频文件评估模型性能。其在图像和视频文件上的准确率分别为80.6\%和70.4\%。Oyewola等人表明，在识别木薯植物不同病害方面，带有残差连接的深度学习优于普通的卷积神经网络（CNN）。

Picon等人使用带有50层的深度残差神经网络（ResNet），在每个卷积层后加入批量归一化和ReLU激活函数，识别了三种不同的小麦病害。在德国采集的实时田间图像中，他们记录的准确率为96\%。Durmus等人使用SqueezeNet架构识别不同的番茄叶片病害。SqueezeNet的结构类似于AlexNet，但其大小为2.9MB，而AlexNet的大小为227.6MB。Hu等人通过修改Cifar10快速CNN模型，将标准卷积替换为深度可分卷积，识别了四种不同的茶叶病害，准确率提升至92.5\%。Atila等人使用EfficientNet架构识别植物病害，结果表明EfficientNet的性能优于AlexNet、VGG等标准CNN模型。在PlantVillage数据集上，EfficientNetB4的准确率达到了99.97\%。EfficientNet由于参数量较少，训练时间比其他深度学习模型更短。

Chen等人使用带有Inception层的预训练VGG模型（称为INC-VGGN）识别了不同的玉米和水稻病害。他们替换了VGGNet的全连接层，并添加了两个Inception层。在水稻病害上的平均测试准确率为92\%，玉米病害上的准确率为80.38\%。Li等人使用预训练VGG16模型的浅层CNN识别玉米、苹果和葡萄的不同病害。他们仅使用VGG16架构的前四层和一个全局池化层。浅层CNN用于特征提取，并通过主成分分析（PCA）减少维度。SVM和随机森林（RF）分别获得了94\%的F1分数。Zeng和Li使用自注意力CNN识别不同的农作物病害。注意力网络在提取关键区域图像特征方面表现出色。

\tab{t1-1}{0.7}{植物病害鉴定相关研究总结}
\mySection{资料与方法}{s3-zh}
%\section{资料与方法} \label{s3-zh}
\mySubsection{卷积神经网络}
卷积神经网络是一类在计算机视觉任务（如模式识别和分类）中非常有效的神经网络。卷积神经网络的优势在于能够自动从训练图像中学习和提取特征，而传统方法需要手动提取特征。卷积神经网络包含不同的层次结构：卷积层、池化层和全连接层。卷积层是卷积神经网络的核心组成部分，从输入图像中提取特征。卷积层由一组称为核的数字数组组成，应用于输入数据后生成称为特征图的输出。不同的卷积核用于提取不同类型的特征。卷积层的数量取决于输入图像的大小。

卷积层后进行池化操作，负责减少卷积特征图的维度。池化层通过下采样减少特征图的尺寸，从而降低处理数据所需的计算复杂度。池化操作有多种类型，包括最大池化、最小池化和平均池化。卷积层或池化层的输出特征图最终转换为一维向量，每个输入与输出之间由权重相连。这个层称为密集层，可以包含一个或多个全连接层。最终的全连接层的输出数量等于类别的数量。

\mySubsection{残差网络}
卷积神经网络在分类任务中可能达到较高的性能。然而，随着网络深度的增加，模型的准确率趋于饱和，并迅速下降。为了解决这个问题，He等人在2015年提出了一种深度残差学习网络ResNet。

在深度学习中，通过在网络中使用残差连接，可以训练更深层次的网络，并解决由于网络深度增加而导致的梯度消失问题。ResNet引入了一种称为“恒等映射”的跳跃连接，将前一层的输出与后续层的输出相结合。恒等映射无需生成额外参数，因此ResNet能够训练比VGG等其他网络更深且复杂度更低的模型。

\fig{f1-1}{0.5}{残差网络的基本框图}

\mySubsection{深度可分离卷积}
Chollet在Xception模型中引入了深度可分离卷积。后来，Howard等人在MobileNet架构中使用了深度可分离卷积。深度可分离卷积将标准卷积分解为深度卷积和1×1逐点卷积。在标准卷积中，过滤输入图像并组合这些值需要一步。图\ref{f1-2-zh}显示了深度可分离卷积的框图。深度层执行过滤操作，逐点层组合深度层的输出。深度可分离卷积的计算成本计算为：

\begin{equation*} D_{K}^{2}\times M\times D_{F}^{2}+M\times N\times D_{K}^{2}\tag{1}\end{equation*}

而标准卷积的计算成本是：

\begin{equation*} D_{K}^{2}\times M\times N \times D_{F}^{2}\tag{2}\end{equation*}

其中DF是方形输入图像的维度，DK是内核的维度，M是通道数，N是内核/过滤器的数量。

\fig{f1-2}{0.5}{深度可分离卷积}

\mySubsection{植物病害识别的新型卷积神经网络方法}
本文提出了一种基于Inception和残差连接的新型轻量级卷积神经网络，其参数数量远少于InceptionV3、ResNet50及其他深度学习模型。Inception架构由Szegedy等人于2015年提出，被命名为GoogleNet（Inception-v1）。随后，该网络通过增加因式分解进一步优化，被称为Inception-v3。Inception架构与典型的卷积神经网络不同，它通过同时执行多个卷积和池化操作以提取更优的特征，并将不同卷积核尺寸的输出进行拼接。Inception v3架构由多个Inception A块、Reduction A块、Inception B块和Reduction B块组成，其结构如图\ref{f1-3-zh}(a)和图\ref{f1-4-zh}(a)所示。Inception A块 包含一个1×1卷积层，后接一个1×1卷积层和一个3×3卷积层，或者一个1×1卷积层和一个5×5卷积层。此外，还包含一个3×3最大池化层，后接一个1×1卷积层。Inception B块包含一个1×1卷积层，后接一个1×1卷积层和一个7×7卷积层，或者一个1×1卷积层和两个连续的7×7卷积层。此外，还包含一个3×3最大池化层，后接一个1×1卷积层。Reduction A块包括一个3×3最大池化层、一个3×3卷积层和一个1×1卷积层，后接一个3×3卷积层。Reduction B块包括一个3×3最大池化层、一个3×3卷积层，后接一个1×1卷积层和一个7×7卷积层，后接一个3×3卷积层。图\ref{f1-3-zh}(a)和图\ref{f1-4-zh}(a)展示了Inception-v3架构中Inception A块和B块的结构图。

\fig{f1-3}{0.7}{Inception架构(a)原始inception-A块(b)修改后的inception-A块}

\fig{f1-4}{0.7}{Inception架构(a)原始inception-B块(b)修改后的inception-B块}

在本文工作中，提出了一种新型卷积神经网络模型，该模型结合了Inception架构的标准卷积和深度可分离卷积（Depthwise Separable Convolution）。Inception A块中的3×3卷积层被替换为3×3深度可分离卷积（即3×3深度卷积和1×1点卷积）。5×5卷积层被两个3×3深度可分离卷积所取代，如图\ref{f1-3-zh}(b)所示。Inception B块中的7×7卷积层被7×7深度可分离卷积（7×7深度卷积和1×1点卷积）取代，如图\ref{f1-4-zh}(b)所示。Reduction A块中的3×3卷积层被1×1卷积层和3×3深度可分离卷积取代。Reduction B块中的3×3和7×7卷积层被1×1卷积层和3×3深度可分离卷积所取代。表\ref{t1-2-zh}和表\ref{t1-3-zh}分别展示了原始Inception A块与经过深度可分离卷积修改后的Inception A块所需的参数数量对比。从表中可以看出，修改后的Inception A块所需参数量显著减少。

\tab{t1-2}{0.7}{原始Inception-A块中所需的参数}

\tab{t1-3}{0.7}{改进的Inception-A块中具有深度可分离卷积所需的参数}

图\ref{f1-5-zh}展示了所提出的卷积神经网络模型架构，该模型用于识别植物病害。模型主要包含以下部分：卷积层、批量归一化（Batch Normalization）和激活层、带有深度可分离卷积的Inception块、池化层和全连接层。

在该架构中，标准卷积被深度可分离卷积取代。模型采用了一个标准卷积层、三个深度可分离卷积层、两个最大池化层和一个全局平均池化层。此外，模型包括三个带有残差连接的改进型Inception A块，后接改进型Reduction A块，以及三个带有残差连接的改进型Inception B块，后接改进型Reduction B块。每个卷积层后均添加批量归一化和ReLU激活函数，以提升模型性能并加速训练过程。在全局平均池化后，添加了Dropout层，以减少模型过拟合的风险。该模型的总参数数量为428,100，而标准Inception V3模型的参数数量高达23,851,784。结果表明，所提出的模型相比Inception V3减少了约70\%的参数量，同时在准确率方面保持了较高水平。


\fig{f1-5}{0.5}{提出的卷积神经网络方法在植物疾病识别中的应用}
\mySection{结果与讨论}{s4-zh}
%\section{结果与讨论} \label{s4-zh}
\mySubsection{数据集}
本文使用三个不同的植物病害数据集对模型性能进行评估，包括水稻病害数据集、木薯病害数据集和PlantVillage数据集。PlantVillage数据集是一个大型且可用的植物病害数据集，本文使用了其中的玉米、马铃薯和番茄病害图像。PlantVillage数据集的图像在统一背景和实验室设置条件下拍摄，而水稻病害数据集的图像在田间实时采集，木薯数据集的图像在田间条件下拍摄，并包含多片叶子。水稻病害数据集包含5932张图像，分为四类：1584张细菌性条斑病图像，1440张稻瘟病图像，1600张褐斑病图像，以及1308张黄矮病图像。木薯病害数据集包含5656张图像，包括五个类别：316张健康木薯叶片图像，466张木薯细菌性枯萎病图像，1443张木薯褐条病图像，773张木薯绿螨病图像，以及2658张木薯花叶病图像。木薯病害数据集的图像包含复杂背景，且单张图像中存在多片叶子。数据集按照80:20的比例随机划分为训练集和测试集，图像尺寸调整为256×256像素。图\ref{f1-6-zh}展示了不同数据集的示例图像，表\ref{t1-4-zh}、表\ref{t1-5-zh}和表\ref{t1-6-zh}详细描述了数据集的组成、病害类别以及每类图像数量。

\tab{t1-4}{0.7}{Plantvillage数据集（玉米、马铃薯、番茄）数据描述}

\tab{t1-5}{0.7}{水稻病害数据描述}

\tab{t1-6}{0.7}{木薯数据集的数据描述}

\tab{f1-6}{0.5}{Plantvillage数据集、水稻和木薯植物数据集的样本图像}

\mySubsection{实验结果}
为了评估模型的性能，本文使用了多项性能指标，包括参数数量、准确率、精确率、召回率和F1分数，其计算公式如下：

\begin{align*} Accuracy=&\frac {TP+TN}{TP+FP+TN+FN} \tag{3}\\ Precision=&\frac {TP}{TP+FP} \tag{4}\\ Recall=&\frac {TP}{TP+FN} \tag{5}\\ f1-score=&\frac {2\times precision\times recall }{precision + recall}\tag{6}\end{align*}

其中，TP为真阳性，TN为真阴性，FP为假阳性，FN为假阴性。

表\ref{t1-7-zh}展示了所提出模型在不同数据集上的性能表现。经过50轮训练后，该模型在PlantVillage数据集上的最高训练准确率和损失分别达到99.81\%和0.0015，验证准确率和损失分别为99.39\%和0.0549。在水稻病害数据集上，模型取得了99.94\%的最高训练准确率和0.0030的训练损失，验证准确率和损失分别为99.66\%和0.0041。为了验证模型的健壮性，本文还使用了木薯病害数据集，该数据集的图像在真实田间条件下拍摄，包含复杂背景，并且单张图像中可能包含多片叶子。与PlantVillage和水稻数据集相比，由于数据不平衡和图像复杂性，木薯病害数据集的训练准确率和验证准确率分别为98.17\%和76.59\%。与PlantVillage和水稻病害数据集相比，木薯数据集的性能较低，这可能是由于数据不平衡以及图像背景复杂造成的。图\ref{f1-7-zh}至图\ref{f1-9-zh}展示了模型在PlantVillage、水稻和木薯病害数据集上的训练和验证准确率以及损失情况。

\tab{t1-7}{0.7}{基于深度学习的实施方法总结}

将数据集分成80\%-20\%的训练集和验证集后，我们对模型进行最多50次训练，并评估训练集和验证集上的性能。图7-9分别显示了所提模型在PlantVillage、水稻和木薯数据集上的训练和验证的准确率和损失。从图\ref{f1-7-zh}至图\ref{f1-9-zh}可以看出，所提模型以较少的参数提供了令人满意的性能。

\tab{f1-7}{0.7}{(a)PlantVillage数据集上的训练和验证准确率(b)训练和验证损失}

\tab{f1-8}{0.7}{(a)水稻病害数据集的训练和验证准确率(b)训练和验证损失}

\tab{f1-9}{0.7}{(a)训练和验证准确度(b)木薯植物数据集的训练和验证损失}

我们还计算了混淆矩阵来评估模型的性能。表8显示了实施模型在三种植物数据集上的测试准确度、精确度、召回率和f1分数方面的性能。从表\ref{t1-8-zh}可以看出，水稻植物数据集的测试准确度高于PlantVillage和木薯数据集。图\ref{f1-10-zh}给出了实施模型在不同数据集上的性能指标。从图\ref{f1-10-zh}可以看出，水稻和plantvillage数据集的平均预测准确度、精确度、召回率和F1分数超过99%。

\fig{f1-10}{0.5}{所提出的模型在不同数据集上的性能指标}

\tab{t1-8}{0.7}{所提模型在测试图像上的性能指标}

\mySubsection{模型性能与健壮性比较}
为了验证所提出模型的稳定性，本文采用了5折交叉验证方法对病害数据集进行评估。数据集被随机分为五个相等部分，每次选择其中一部分作为测试集，其余部分作为训练集。基于不同的训练-测试划分，可以获得模型在不同数据集上的表现。表\ref{t1-9-zh}展示了所提出模型在交叉验证过程中的性能表现。结果表明，每个数据集不同折之间的性能差异较小。在PlantVillage数据集上，模型准确率在99.29\%到99.37\%之间浮动；在水稻病害数据集上，准确率在99.33\%到99.66\%之间；而在木薯病害数据集上，准确率范围为76.42\%到76.58\%。结果表明，本文提出的CNN模型在植物病害识别任务中具有良好的稳定性和一致性。

\tab{t1-9}{0.7}{基于k倍交叉验证的CNN结果}

\mySubsection{与预训练网络的性能比较 }
本文还对比了多种预训练深度学习模型，包括VGG16、VGG19、InceptionV3、ResNet50和DenseNet201，并将这些模型的性能与本文提出的CNN模型进行对比。性能比较指标包括模型在不同数据集上的准确率以及每轮训练所需的时间。表10展示了所提出模型与其他预训练模型在不同数据集上的性能对比。结果显示，本文模型在PlantVillage数据集上的测试准确率为99.39\%，在水稻病害数据集上的准确率为99.66\%，在木薯病害数据集上的准确率为76.59\%。此外，本文模型的参数数量远少于InceptionV3模型。每轮训练的时间显著减少，说明本文模型在小型设备或计算资源受限的环境中更具实际应用价值。

\tab{t1-10}{0.7}{与预训练网络的性能比较}

\mySubsection{与现有文献的性能比较}
为了进一步验证所提出模型的有效性，本文将模型的性能与现有文献中的深度学习模型进行了对比。表\ref{t1-11-zh}展示了本文模型与其他模型的性能比较。结果表明，本文模型在准确率、参数数量和训练时间等方面均优于现有模型。表\ref{t1-11-zh}的结果还显示，本文模型所需参数数量远少于其他深度学习模型，因此在训练过程中耗时更少。与其他模型主要在PlantVillage数据集（实验室环境下）进行测试不同，本文模型在真实田间环境下的数据集（如水稻和木薯病害数据集）上表现出较强的健壮性和泛化能力。综上所述，所提出的CNN模型在植物病害识别任务中展现出更高的准确率、更少的参数量和更快的训练速度，同时在资源受限的设备上更具部署优势。

\tab{t1-11}{0.7}{不同深度学习模型的性能比较}
\mySection{结论}{s5-zh}
%\section{结论} \label{s5-zh}
	深度学习是一种在图像模式识别领域中具有前沿性的先进技术，在植物病害识别方面表现出极高的有效性。本文提出了一种基于Inception和残差连接的新型卷积神经网络（CNN）模型，该模型能够有效地对植物病害进行分类。此外，在Inception架构中引入了深度可分离卷积，从而减少了约70\%的参数量，显著降低了计算成本。因此，与标准CNN模型相比，训练该网络所需的时间大大减少。实验结果表明，所提出的模型在不同植物病害数据集上均取得了较高的识别准确率。为了验证模型的健壮性，本文采用了三个不同的植物病害数据集进行测试。该模型在PlantVillage数据集上的测试准确率为99.39\%，在水稻病害数据集上的准确率为99.66\%，在木薯病害数据集上的准确率为76.59\%。在不平衡数据集上，其他研究中使用普通卷积神经网络和深度残差神经网络所取得的准确率分别为52.87\%和46.26\%，而在平衡数据集上，其最高准确率可达80.6\%。相比之下，本文模型在不平衡木薯病害数据集上取得了76.59\%的准确率，表现优于现有模型。在水稻病害数据集上，Sethy等人的模型取得了98.25\%的准确率，而本文模型在相同数据集上达到了更高的99.66\%的准确率。未来的研究方向包括将该模型应用于农业领域的其他任务，如杂草检测、害虫识别等。此外，还将探索在不同种类的植物病害数据集上进行模型验证，这些数据集将涵盖不同的植物种类、图像类型以及来自不同地理区域的图像数据。未来的工作还将尝试使用基于聚类的无监督技术进行植物病害识别，以进一步提升模型的泛化能力和实用性。
